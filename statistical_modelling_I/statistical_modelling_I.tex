% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames*,x11names*}{xcolor}
%
\documentclass[
]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Statistical Modelling I},
  pdfauthor={Kexing Ying},
  colorlinks=true,
  linkcolor=Maroon,
  filecolor=Maroon,
  citecolor=Blue,
  urlcolor=red,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin = 1.5in]{geometry}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{tikz}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{lipsum}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{physics}
\theoremstyle{definition}
\newtheorem{theorem}{Theorem}
\newtheorem{prop}{Proposition}
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{example}{Example}
\newtheorem*{remark}{Remark}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{lemma}{Lemma}[section]
\newcommand{\diag}{\mathop{\mathrm{diag}}}
\newcommand{\Arg}{\mathop{\mathrm{Arg}}}
\newcommand{\hess}{\mathop{\mathrm{Hess}}}
\newcommand{\Var}{\mathop{\mathrm{Var}}}
\newcommand{\bias}[1]{{\mathop{\mathrm{bias}}}_{#1}}
\newcommand{\se}[1]{{\mathop{\mathrm{SE}}}_{#1}}
\newcommand{\mse}[1]{{\mathop{\mathrm{MSE}}}_{#1}}

\title{Statistical Modelling I}
\author{Kexing Ying}
\date{January 11, 2021}

\begin{document}
\maketitle

{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}
\newpage

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

In this module, we will consider and analyse the relationship between
measurements through the use of statistical models. This is realised in
several ways including quantifying distributions, comparing
distributions and predicting observations. We shall study these methods
through deriving, evaluating and applying estimators, confidence
intervals and hypothesis tests based, first on parametric models, and
later based on the theory of linear models.

\begin{definition}[Statistical Model]
  A statistical model is a specification of the distribution of \(Y\) up to an 
  unknown parameter \(\theta\).
\end{definition}

\begin{definition}[Parameter Space]
  Given a statistical model \(Y\) up to some parameter \(\theta\), the set \(\Theta\) 
  of all possible parameter values is called the parameter space.
\end{definition}

In this module we will assume \(\Theta \subseteq \mathbb{R}^p\) for some
\(p \in \mathbb{N}\) so that we consider \emph{parametric models}. A
\emph{semiparametric model} is a statistical model which parameters
belong to a more general space, e.g.~functions spaces.

As with last years \textbf{Probability and Statistics}, we will denote
the data \(\mathbf{y} = (y_1, \cdots, y_n) \in \mathbb{R}^n\) as a
vector and \(\mathbf{Y} = (Y_1, \cdots, Y_n)\) a random vector. In this
case, the statistical model specifies the joint distribution of
\(Y_1, \cdots, Y_n\) up to some unknown parameter \(\theta\). If
\(Y, \cdots, Y_n\) are independent and identically distributed (iid.),
then we call it a \emph{random sample}.

Furthermore, in some situations, the random vector
\(\mathbf{Y} = (Y_1, \cdots, Y_n)\) might be dependent on random or
nonrandom values \(x_1, \cdots, x_n\). The \(x_i\)'s are an example of
covariates. An example of this could be that, in a clinical trial, some
patients are given a treatment while others received a placebo. If we
would like to model the outcome of the \(i\)-th patient by their
survival time \(Y_i\), it is clear that as covariate for the \(i\)-th
patient, we may use the indicator function for whether or not \(i\)
received the treatment as a covariate.

As another example, say we would like to ask whether or not taller
people have a higher income. To answer this question we might create a
statistical model in which \(Y_i\) is the income, \(x_i\) is the height
and \[Y_i = \beta_0 + x_i \beta_1 + \epsilon_i\] for
\(i = 1, \cdots, n\), \(\epsilon \sim N(0, \sigma^2)\) iid. and
\(\theta = (\beta_0, \beta_1, \sigma^2)\),
\(\Theta = \mathbb{R}^2 \times [0, \infty)\).

Having formulated a model, we can draw inferences from the sample. By
estimating the unknown parameters we attempts to ``fit the model''.
Through this, we receive a model that can provide us with point
estimates, or better yet, tools that can help us make decisions through
some combination of hypothesis tests and confidence intervals.

However, with all statistical models, we have to accept that it will not
perfectly reflect reality. But, that is not the point of statistical
models anyway. Statistical models are meant to be useful and in general
we would like a model to

\begin{itemize}
  \item agree with the observed data reasonably;
  \item be relatively simple;
  \item interpretable, e.g. parameters have a physical interpretation.
\end{itemize}

With these aims in mind, we might conduct sensitivity analysis in which
we discard models that are not adequate for the data through a iterative
process.

\newpage

\hypertarget{point-estimation}{%
\section{Point Estimation}\label{point-estimation}}

From the introduction, we seen that during the process of fitting the
model, we need to estimate \(\theta\) in the statistical model, and
furthermore, during the inference process, we need to point estimate,
interval estimate or hypothesis test to address our question. We recall
from first year that this can be achieved through several methods and we
shall quickly review them here.

\hypertarget{review}{%
\subsection{Review}\label{review}}

We recall the following definitions.

\begin{definition}[Realisation, Statistic, Estimate, Estimator]
~
\begin{itemize}
  \item Data \(y_1, \cdots, y_n\) is called a realisation of \(Y_1, \cdots, Y_n\).
  \item A function \(t\) of observable random variables is called a statistic.
  \item An estimate of \(\theta\) is \(t(y_1, \cdots, y_n)\).
  \item An estimator of \(\theta\) is \(T = t(Y_1, \cdots, Y_n)\).
\end{itemize}
\end{definition}

\begin{example}
  Let \(Y_1, \cdots, Y_n \sim N(\mu, 1)\) iid. for some unknown \(\mu \in \mathbb{R}\).
  There are many methods for estimating \(\mu\). 
  \begin{itemize}
    \item the sample mean \(\hat{\mu} = \frac{1}{n} \sum y_i\);
    \item the sample median;
    \item the \(k\)-trimmed mean where we discard the highest and lowest \(k\) observed \(y_i\)
      before computing the mean;
    \item \(\cdots\) 
  \end{itemize}
  For the sample mean estimate, the corresponding estimator is 
  \(T = \bar{Y} = \frac{1}{n}\sum Y_i\).
\end{example}

As we can see from the example, there are many possible estimations for
the same parameter. To justify the use of a specific estimator, one
might use a frequentist's perspective and generate many data and
tabulate the results of each estimator. Through this process, one can
justify a particular estimator through observed data.

As estimators are random variables, we can formalise this idea by
considering properties of its sampling distribution (that is the
distribution of the estimator), e.g.~
\[\mathbb{P}_\theta(T \in \mathcal{A}), \hspace{2mm} E_\theta(T), \hspace{2mm} {\mathop{\mathrm{Var}}}_\theta(T), \cdots\]
We saw this idea last year in the form of \emph{bias} and \emph{mean
square error}. We recall the definitions here.

\begin{definition}[Bias]
  Let \(T\) be an estimator of \(\theta \in \Theta \subseteq \mathbb{R}\). Then 
  the bias of \(T\) is 
  \[{\mathop{\mathrm{bias}}}_{\theta}(T) = E_\theta(T) - \theta.\]
  If \({\mathop{\mathrm{bias}}}_{\theta}(T) = 0\) for all \(\theta \in \Theta\), then we say \(T\) is 
  unbiased for \(\theta\).
\end{definition}

If the parameter space is higher dimensional, say
\(\Theta \subseteq \mathbb{R}^k\), we may be instead be interested in
the value of \(g(\theta)\) for some \(g : \Theta \to \mathbb{R}\). Then,
we can naturally extend the definition of bias to this by
\[{\mathop{\mathrm{bias}}}_{\theta}(T) = E_\theta(T) - g(\theta).\]

\begin{example}
  Let \(Y_1, \cdots, Y_n \sim N(\mu, \sigma^2)\) iid. 
  \(\theta = (\mu, \sigma^2) \in \Theta = \mathbb{R} \times (0, \infty)\). Then, 
  say if we are in \(\mu\), we may define \(g : \Theta \to \mathbb{R} : 
  (\mu, \sigma^2) \mapsto \mu\).
\end{example}
\begin{definition}[Mean Square Error]
  Let \(T\) be an estimator of \(\theta \in \Theta \subseteq \mathbb{R}\). Then 
  the mean square error of \(T\) is 
  \[{\mathop{\mathrm{MSE}}}_{\theta}(T) = E_\theta[(T - \theta)^2].\]
\end{definition}

In addition to this, we have the standard error of a estimator

\begin{definition}[Standard Error]
  Let \(T\) be an estimator of \(\theta \in \Theta \subseteq \mathbb{R}\). Then 
  the standard error of \(T\) is 
  \[{\mathop{\mathrm{SE}}}_{\theta}(T) = \sqrt{{\mathop{\mathrm{Var}}}_\theta(T)}.\]
\end{definition}

From last year, we saw the following proposition.

\begin{prop}
  Let \(T\) be an estimator of \(\theta \in \Theta \subseteq \mathbb{R}\). Then 
  \[{\mathop{\mathrm{MSE}}}_{\theta}(T) = {\mathop{\mathrm{Var}}}_\theta(T) + ({\mathop{\mathrm{bias}}}_{\theta}(T))^2.\]
\end{prop}

If we restrict out estimators to be unbiased, often times, we find that
the remaining possible estimators well-behaved and we can often find the
best estimators by minimising the MSE. However, a biased estimator might
have a small MSE than an unbiased estimator (recall sample variance),
and it is not necessarily true that such an estimator even exists.

\hypertarget{cramuxe9r-rao-lower-bound}{%
\subsection{Cramér-Rao Lower Bound}\label{cramuxe9r-rao-lower-bound}}

As the mean square error provide us with a method of quantifying how
good an estimator is, we are motivated by minimising the mean square
error for a family of estimators. That is, if \(\theta \in \Theta\) is a
parameter, then is there an estimator \(T\) of \(\theta\) such that for
all estimators of \(\theta\), \(S\),
\[{\mathop{\mathrm{MSE}}}_{\theta}(T) \le {\mathop{\mathrm{MSE}}}_{\theta}(S).\]
Unfortunately, the answer to this question is in general, no, however,
for unbiased estimators, the answer is often yes. Indeed, if \(T\) is an
unbiased estimator, then,
\[{\mathop{\mathrm{MSE}}}_{\theta}(T) = {\mathop{\mathrm{Var}}}_\theta(T) = {\mathop{\mathrm{bias}}}_{\theta}(T)^2 = {\mathop{\mathrm{Var}}}_\theta(T),\]
so it suffices to minimise the variance.

\begin{theorem}[Cramér-Rao Lower Bound]
  Suppose \(T = T(X)\) is an unbiased estimator for \(\theta \in \Theta \subseteq \mathbb{R}\) 
  based on \(X = (X_1, \cdots, X_n)\) with joint pdf \(f_\theta(x)\). Then under 
  mild regularity conditions (which is elaborated on in the proof below),
  \[{\mathop{\mathrm{Var}}}_{\theta}(T) \ge \frac{1}{I(\theta)},\]
  where 
  \[I(\theta) = E_\theta\left[\left\{\pdv{\theta} \log f_\theta(X)\right\}^2\right],\]
  and we call \(I(\theta)\) the \textit{Fisher information} of the sample.
\end{theorem}

By computing, we find the Fisher information to equal the following.
\[I(\theta) = -E_\theta\left[\pdv[2]{\theta} \log f_\theta(X) \right].\]
Indeed, \[\begin{split}
  E_\theta\left[\pdv[2]{\theta} \log f_\theta(X) \right] 
    & = E_\theta\left[\pdv{\theta} \frac{f'_\theta(X)}{f_\theta(X)}\right]\\
    & = E_\theta\left[- \frac{f'_\theta(X)}{f^2_\theta(X)}f'_\theta(X) + \frac{f''_\theta(X)}{f_\theta(X)}\right]\\
    & = E_\theta\left[-\left(\pdv{\theta} \log f_\theta(X)\right)^2\right] + E_\theta\left[ \frac{f''_\theta(X)}{f_\theta(X)}\right].   
\end{split}\] So, the result follows as, \[\begin{split}
  E_\theta\left[ \frac{f''_\theta(X)}{f_\theta(X)}\right] 
    & = \int_{x \in A} \frac{f''_\theta(x)}{f_\theta(x)}f_\theta(x) \dd x\\
    & = \int_{x \in A} f''_\theta(x) \dd x = \pdv[2]{\theta} \int_{x \in A} f_\theta(x) \dd x = 0,
\end{split}\] where we denoted \(A\) as the support of \(f_\theta\).
This is a useful identity whenever the second derivative is easy to
compute.

\begin{corollary}
  Suppose \(X_1, \cdots, X_n\) is a random sample. Then, is \(f_\theta^{(1)}\) is 
  the pdf of single observation, then 
  \[I_f(\theta) = n I_{f_\theta^{(1)}}(\theta).\]
\end{corollary}
\proof

Since a random sample is iid. \(f_\theta(x) = \prod f_\theta^{(1)}\) and
so
\[I_{f}(\theta) = -E_\theta\left[\pdv[2]{\theta}\log f_\theta(X) \right] 
    = \sum_{i = 1}^n - E_\theta\left(\pdv[2]{\theta} \log f_\theta^{(1)}(X_i)\right)
    = n I_{f_\theta^{(1)}}(\theta).\] \qed

From this, we can conclude that the Fisher information is proportional
to the sample size.

\begin{example}
  Let us find the Fisher information for the random sample 
  \(X_1, \cdots, X_n \sim \text{Bern}(\theta)\).
  
  By the above corollary, we have \(I_f(\theta) = n I_{f_\theta^{(1)}}(\theta)\).
  So, since the pmf of a Bernoulli random variable is 
  \(f_{\theta}^{(1)}(x) = \theta^x(1 - \theta)^{1 - x}\), we have 
  \[\pdv{\theta} \log f_\theta^{(1)}(x) = \frac{x}{\theta} - \frac{1 - x}{1 - \theta} 
    = \frac{x - \theta}{\theta(1 - \theta)},\]
  hence,
  \[I_{f_\theta^{(1)}}(\theta) = E\left[\left(\frac{x - \theta}{\theta(1 - \theta)}\right)^2\right] 
    = \frac{1}{\theta^2(1 - \theta)^2} \mathop{\mathrm{Var}}(X) = \frac{1}{\theta(1 - \theta)}.\]
  Thus, the Fisher information of the random sample is just 
  \(I_f(\theta) = n / \theta(1 - \theta)\).

  With the Fisher information, we can apply the Cramér-Rao lower bound theorem 
  allowing us to conclude that an unbiased estimator \(T\) for \(\theta\) has variance 
  \(\mathop{\mathrm{Var}}(T) \ge \theta(1 - \theta) / n = \mathop{\mathrm{Var}}(\bar{X})\). This allows us to conclude 
  that the sample mean \(\bar{X}\) minimises the mean square error among unbiased 
  estimators for \(\theta\). 
\end{example}

Let us now prove the Cramér-Rao lower bound theorem.

\proof (Cramér-Rao lower bound theorem). Let us first specify the
regularity conditions for the Cramér-Rao lower bound theorem.

\begin{itemize}
    \item Assume that the set \(A := \text{supp} f_\theta = \{x \in \mathbb{R}^n \mid f_\theta(x) > 0\}\)
      is independent of \(\theta\).
    \item \(\Theta\) is an open interval in \(\mathbb{R}\).
    \item For all \(\theta \in \Theta\) there exists \(\pdv{f_\theta}{\theta}\).
    \item Differentiation and integration commutes (for the specific cases where it 
      is used).
  \end{itemize}

As we saw last year, the space of random variables form an inner product
space with the inner product \[\langle X, Y \rangle = E[XY],\] and so,
the Cauchy-Schwarz inequality applies. That is for all random variables
\(X, Y\) \[[E(XY)]^2 \le E(X^2)E(Y^2).\] So, we have \[\begin{split}
    {\mathop{\mathrm{Var}}}_\theta(T) I_f(\theta) & = E_\theta[(T - E_\theta T)^2] 
      E_\theta\left[\left(\pdv{\theta}\log f_\theta(X)\right)^2\right]\\
      & \ge \left(E_\theta\left[(T - E_\theta(T)) \pdv{\theta}\log f_\theta(X) \right]\right)^2.
    \end{split}\] Thus, it suffices to show that the expectation on the
right hand side evaluates to 1. \[\begin{split}
    E_\theta\left[(T - E_\theta(T)) \pdv{\theta}\log f_\theta(X) \right] & =
      E_\theta\left[(T - E_\theta(T)) \frac{\pdv{\theta}f_\theta(X)}{f_\theta(X)}\right]\\
      & = \int_{x \in A} (T(x) - E_\theta(T))\frac{\pdv{\theta}f_\theta(x)}{f_\theta(X)} f_\theta(x) \dd x\\
      & = \int_{x \in A} T(x) \pdv{\theta}f_\theta(x) \dd x - \int_{x \in A} E_\theta(T) \pdv{\theta}f_\theta(x) \dd x\\
      & = \pdv{\theta} \int_{x \in A} T(x) f_\theta(x) \dd x - E_\theta(T) \pdv{\theta} \int_{x \in A} f_\theta(x) \dd x\\
      & = \pdv{\theta} E_\theta(T) - 0 = \pdv{\theta}\theta = 1.
   \end{split}\] \qed

\hypertarget{asymptotic-properties-of-estimators}{%
\subsection{Asymptotic Properties of
Estimators}\label{asymptotic-properties-of-estimators}}

While the Cramér-Rao lower bound theorem provides us with a lower bound
for the variance for non-biased estimators, as we have previously seen,
it is not always true that there exists an unbiased estimator. So,
rather than giving up, we instead study the estimators as the sample
size becomes large.

As we have seen, evaluating an estimator \(T = T(X_1, \cdots, X_n)\) of
\(\theta\) depends on its \emph{sampling distribution}. From the
sampling distribution, one can possibly find properties about the
estimator such as is bias, mean square error and so on. However, it is
not necessarily true that an estimator has a closed form. Indeed, often
times, the estimator is defined as a solution to some equation.

To simplify this, one often consider \(T_n = T_n(X_1, \cdots, X_n)\) as
a sequence of random variables indexed by \(n \in \mathbb{N}\) and
consider the stochastic convergence of the variables in question. We
recall from last term's probability course, there are three different
notions of convergence for random variables,

\begin{itemize}
  \item convergence in probability;
  \item convergence almost surely (almost everywhere);
  \item convergence in distribution.
\end{itemize}

Let us quickly define them here again.

\begin{definition}[Convergence in Probability]
  Let \((X_n)_{n = 1}^\infty\) be a sequence of random variables. Then, \((X_n)\) 
  converges to the random variable \(X\) in probability if for all \(\epsilon > 0\),
  \[\lim_{n \to \infty} \mathbb{P}(|X_n - X| > \epsilon) = 0.\]
\end{definition}
\begin{definition}[Convergence Almost Surely]
  Let \((X_n)_{n = 1}^\infty\) be a sequence of random variables. Then, \((X_n)\) 
  converges to the random variable \(X\) almost surely if 
  \[\mathbb{P}\left(\lim_{n \to \infty} X_n = X\right) = 1,\]
  where \(\lim_{n \to \infty} X_n = X\) is denoting the event 
  \[\{\omega \in \Omega \mid X_n(\omega) \to X(\omega)\}.\]
  With other words, \(X_n \to X\) almost surely, if the set of points \(\omega\) 
  such that \(X_n(\omega)\) does not converge to \(X(\omega)\) has measure 0.
\end{definition}
\begin{definition}
  Let \((X_n)_{n = 1}^\infty\) be a sequence of random variables. Then, \((X_n)\) 
  converges to the random variable \(X\) with cdf \(F_X\) in distribution if 
  \[\lim_{n \to \infty} \mathbb{P}(X_n \le x) = F_X(x),\]
  for all \(x\) at which \(F_X\) is continuous.
\end{definition}

We also recall the following chain of implications,
\[X_n \to_\text{as} X \implies X_n \to_\text{p} X \implies X_n \to_\text{d} X.\]
If \(X = c\) is a constant, then
\[X_n \to_\text{p} X \iff X_n \to_\text{d} X.\] We apply this notion
onto estimators.

\begin{definition}[Consistency]
  A sequence of estimators \((T_n)_{n = 1}^\infty\) for \(g(\theta)\) is called 
  (weakly) consistent if for all \(\theta \in \Theta\), \(\epsilon > 0\)
  \[\lim_{n \to \infty} \mathbb{P}(|T_n - g(\theta)| > \epsilon) = 0.\]
\end{definition}

While it is possible to prove consistency for certain estimators, it is
often a non-trivial task. Instead, we often look at whether a sequence
of estimators are asymptotically unbiased and prove the a special class
of these estimators are consistent.

\begin{definition}[Asymptotically Unbiased Estimators]
  A sequence of estimators \((T_n)_{n = 1}^\infty\) for \(g(\theta)\) is called 
  asymptotically unbiased if for all \(\theta \in \Theta\), 
  \[E_\theta(T_n) \to g(\theta).\]
\end{definition}

We see that \(E_\theta(T_n)\) is simply a value and this is simply the
convergence for real sequences.

Before moving on to prove results about estimators, let us quickly
recall the Markov inequality.

\begin{prop}
  Let \(X\) be a random variable with \(X(\Omega) \subseteq [0, \infty)\), then 
  for all \(a \in \mathbb{R}\),
  \[\mathbb{P}(|X| \ge a) \le \frac{E(|X|)}{a}.\]
\end{prop}
\proof

See first year notes. \qed

\begin{lemma}[MSE Consistency]
  Let \((T_n)_{n = 1}^\infty\) be asymptotically unbiased for \(g(\theta)\) for 
  all \(\theta \in \Theta\). Then, if \({\mathop{\mathrm{Var}}}_\theta(T_n) \to 0\) as \(n \to \infty\), 
  \(T_n\) is consistent for \(g(\theta)\).
\end{lemma}
\proof

Let \(\epsilon > 0\), then, by Markov's inequality, \[\begin{split}
    \mathbb{P}_\theta(|T_n - g(\theta)| & \ge \epsilon) 
    = \mathbb{P}_\theta((T_n - g(\theta))^2 \ge \epsilon^2)
    \le \frac{1}{\epsilon^2} E_\theta(T_n - g(\theta))^2 \\
    & = \frac{{\mathop{\mathrm{MSE}}}_{\theta}(T_n)}{\epsilon^2} = 
    \frac{1}{\epsilon}({\mathop{\mathrm{Var}}}_\theta(T_n) + (E_\theta(T_n) - g(\theta))^2). 
  \end{split}\] Since the right hand side tends to 0 as
\(n \to \infty\), so is the left hand side. \qed

Thus, to show that a sequence of estimators is consistent, it suffices
to show that it is asymptotically unbiased and its variance tends to 0.

However, while consistency is a nice property for a sequence of
estimators to have, it is a very minimal requirement. So, in order to
derive hypothesis tests and confidence intervals, we also need the
sampling distribution of \(T_n\). As we have seen previously, the sample
mean estimators \(T_n\) for a normal distribution \(N(\theta, 1)\) has
distribution \(T_n \sim N(\theta, 1 / n)\), and so, by centring and
scaling, we have \[\sqrt{n}(T_n - \theta) \sim N(0, 1),\] for all
\(n \ge 1\). This means we can work with the CDF of \(T_n\) allowing us
to easily analyse the behaviours of these estimators. However, this is
in general not the case and in most cases, we cannot derive easily the
distributions of the estimators. Nonetheless, often, we may approximate
their distribution with a normal distribution.

\begin{definition}[Asymptotically Normal]
  A sequence of estimators \(T_n\) for \(\theta \in \mathbb{R}\) is asymptotically 
  normal if, for some \(\sigma^2(\theta)\), 
  \[\sqrt{n}(T_n - \theta) \to N(0, \sigma^2(\theta)),\]
  in distribution.
\end{definition}

From last term, we recall the central limit theorem (CLT).

\begin{theorem}[Central Limit Theorem]
  Let \(Y_1, \cdots, Y_n\) be iid. random variables with \(E(Y_i) = \mu\) and 
  \(\mathop{\mathrm{Var}}(Y_i) = \sigma^2 < \infty\). Then the sequence \(\sqrt{n}(\bar{Y} - \mu)\) 
  converges in distribution to a \(N(0, \sigma^2)\) distribution.
\end{theorem}
\proof

See the \emph{probability for statistics} course. \qed

The central limit theorem allows us to conclude that a large class of
estimators are asymptotically normal. Indeed, sample means and
estimators which can be written as a combination of sample means under
weak conditions are certainly asymptotically normal. However, we would
also consider other estimators.

\begin{lemma}[Slutsky's lemma]
  Let \(X_n, X\) and \(Y_n\) be random variables (or random vectors). If \(X_n \to X\) 
  in distribution and \(Y_n \to c\) in probability for some constant \(c\), then 
  \begin{itemize}
    \item \(X_n + Y_n \to X + c\) in distribution;
    \item \(Y_n X_n \to cX\) in distribution;
    \item \(Y^{-1}_n X_n \to c^{-1} X\) in distribution if \(c \neq 0\).
  \end{itemize}
\end{lemma}
\proof

See the \emph{probability for statistics} course. \qed

Another useful result for determining whether or not a sequence of
estimators are asymptotically normal is the \(\delta\)-method. The
\(\delta\)-method allows us to consider whether or not the
transformation of a asymptotically normal estimator remains
asymptotically normal.

\begin{theorem}[\(\delta\)-Method]
  Suppose that \(T_n\) is an asymptotically normal estimator of \(\theta\) with 
  \[\sqrt{n}(T_n - \theta) \to_\text{d} N(0, \sigma^2(\theta)),\]
  and \(g : \Theta \subseteq \mathbb{R} \to \mathbb{R}\) is a differentiable 
  function with \(g'(\theta) \neq 0\). Then 
  \[\sqrt{n}(g(T_n) - g(\theta)) \to_\text{d} N(0, g'(\theta)^2 \sigma^2(\theta)).\]
\end{theorem}
\proof

Since \(g\) is differentiable,
\[g(T_n) = g(\theta) + g'(\theta)(T_n - \theta) + o((T_n - \theta)^2),\]
where \(R\) is the remainder. So
\[\sqrt{n}(g(T_n) - g(\theta)) = g'\sqrt{n}(\theta)(T_n - \theta) + o((T_n - \theta)^2).\]
Thus, assuming the remainder is negligible, we have
\[\sqrt{n}(g(T_n) - g(\theta)) \to_\text{d} N(0, g'(\theta)^2 \sigma^2(\theta)).\]
\qed

Lastly, a useful result we will often use (perhaps implicitly) is the
continuous mapping theorem. Alike sequential continuity for metric
spaces, the continuous mapping theorem will allow us to preserve
stochastic convergence under continuous mappings.

\begin{theorem}[Continuous Mapping Theorem]
  Let \(g : \mathbb{R}^k \to \mathbb{R}^m\) be continuous at every point of a set 
  \(C\) such that \(\mathbb{P}(X \in C) = 1\). Then if \(X_n \to X\), 
  then \(g(X_n) \to g(X)\) for all three notions of convergence, i.e. 
  convergence in distribution, in probability and almost surely.
\end{theorem}

\end{document}
